{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取训练集数据...\n",
      "训练集一共有102277条数据\n",
      "(102277, 2820641)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/tfidf_feature.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e55a0078591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0mtrain_data_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./data/new_data/train_set.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mtest_data_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./data/new_data/test_set.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-5e55a0078591>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_data_file)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     feature_transfor.fit(max_feature_cnt, feature_max_df,\n\u001b[1;32m---> 75\u001b[1;33m                          feature_min_df, ngram_range, train_x, train_y)\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mmodel_train_x_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_transfor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Jupyter\\feature.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, max_feature_cnt, feature_max_df, feature_min_df, ngram_range, x_train, y_train)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitModelByData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_vec_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_vec_model_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_feature_model_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/tfidf_feature.model'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from feature import FeatureModel\n",
    "from util import read_train,read_test\n",
    "import csv\n",
    "csv.field_size_limit(500*2014)\n",
    "# 设置tfidf参数\n",
    "max_feature_cnt = 280000\n",
    "feature_max_df = 0.9\n",
    "feature_min_df = 3\n",
    "ngram_range = (1, 2)\n",
    "\n",
    "\n",
    "# 设置文件模型保存路径\n",
    "model_path = 'model/'\n",
    "tfidf_model_name = model_path + 'tfidf_feature.model'\n",
    "best_feature_model_name = model_path + 'best_feature.model'\n",
    "sk_lr_model_name = model_path + 'sklearn.lr.model'\n",
    "\n",
    "class SKLearnLR(object):\n",
    "    \"\"\"\n",
    "    LR for 文本分类\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr_model_name):\n",
    "        self.lr_model_name = lr_model_name\n",
    "        self.init_flag = False\n",
    "\n",
    "    def trainModel(self, train_x, train_y):\n",
    "        self.clf = LR(C=4, dual=True)\n",
    "        self.clf.fit(train_x, train_y)\n",
    "        self.init_flag = True\n",
    "        pickle.dump(self.clf, open(self.lr_model_name, 'wb'), True)\n",
    "\n",
    "    def loadModel(self):\n",
    "        try:\n",
    "            self.clf = pickle.load(open(self.lr_model_name, 'rb'))\n",
    "            self.init_flag = True\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Load model fail, ' + str(e))\n",
    "            sys.exit(1)\n",
    "\n",
    "    def testModel(self, test_x, test_y):\n",
    "        if not self.init_flag:\n",
    "            self.loadModel()\n",
    "\n",
    "        pred_y = self.clf.predict(test_x)\n",
    "\n",
    "        total = len(test_y)\n",
    "        correct = 0\n",
    "        for idx in range(total):\n",
    "            if pred_y[idx] == test_y[idx]:\n",
    "                correct += 1\n",
    "\n",
    "        print('Test LR: ', total, correct, correct * 1.0 / total)\n",
    "\n",
    "    def predictModel(self, test_x):\n",
    "        '''\n",
    "        test_x: darray [samples feature_cnt]\n",
    "        '''\n",
    "        if not self.init_flag:\n",
    "            self.loadModel()\n",
    "\n",
    "        pred_y = self.clf.predict(test_x)\n",
    "        return pred_y.tolist()\n",
    "\n",
    "def train(train_data_file):\n",
    "    train_x, train_y = read_train(train_data_file)\n",
    "\n",
    "    feature_transfor = FeatureModel(tfidf_model_name, best_feature_model_name)\n",
    "\n",
    "    feature_transfor.fit(max_feature_cnt, feature_max_df,\n",
    "                         feature_min_df, ngram_range, train_x, train_y)\n",
    "\n",
    "    model_train_x_feature = feature_transfor.transform(train_x)\n",
    "\n",
    "\n",
    "    # train a single LR model\n",
    "    print('正在训练单个LR model...')\n",
    "    lr_clf = SKLearnLR(sk_lr_model_name)\n",
    "    lr_clf.trainModel(model_train_x_feature, train_y)\n",
    "    print('训练完成.')\n",
    "\n",
    "\n",
    "def predict(test_data_file):\n",
    "    print(\"正在加载已经训练模型进行预测\")\n",
    "    test_ids, test_x = read_test(test_data_file)\n",
    "    feature_transfor = FeatureModel(tfidf_model_name, best_feature_model_name)\n",
    "    feature_transfor.loadModel()\n",
    "    model_test_x_feature = feature_transfor.transform(test_x)\n",
    "\n",
    "    lr_clf = SKLearnLR(sk_lr_model_name)\n",
    "    lr_preds = lr_clf.predictModel(model_test_x_feature)\n",
    "\n",
    "    with open('data/results/05_lr_chi.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow(('id', 'class'))\n",
    "        for test_id, pred in zip(test_ids, lr_preds):\n",
    "            csv_writer.writerow((test_id, int(pred)))\n",
    "\n",
    "    print(\"预测结果完成了，你可以提交了^_^\")\n",
    "\n",
    "def eval(test_data_file):\n",
    "    test_x,test_y = read_train(test_data_file)\n",
    "    feature_transfor = FeatureModel(tfidf_model_name, best_feature_model_name)\n",
    "    feature_transfor.loadModel()\n",
    "    model_test_x_feature = feature_transfor.transform(test_x)\n",
    "\n",
    "    lr_clf = SKLearnLR(sk_lr_model_name)\n",
    "    lr_clf.testModel(model_test_x_feature, test_y)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_data_file='./data/new_data/train_set.csv'\n",
    "    train(train_data_file)\n",
    "\n",
    "    test_data_file='./data/new_data/test_set.csv'\n",
    "    predict(test_data_file)\n",
    "\n",
    "    eval(train_data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
