{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, atan, tan, sin, acos, cos\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "train = pd.read_csv('./chuxing/train_new.csv', low_memory=False)\n",
    "test = pd.read_csv('./chuxing/test_new.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 110227\n"
     ]
    }
   ],
   "source": [
    "# ################################# 准备坐标点数据################################\n",
    "trL = train.shape[0] * 2\n",
    "X = np.concatenate([train[['start_lat', 'start_lon']].values,\n",
    "                    train[['end_lat', 'end_lon']].values,\n",
    "                    test[['start_lat', 'start_lon']].values])\n",
    "# #############################################################################\n",
    "# 对经纬度坐标点进行密度聚类 \n",
    "db = DBSCAN(eps=5e-4, min_samples=3, p=1, leaf_size=15, n_jobs=-1).fit(X)  #原来是10\n",
    "labels = db.labels_\n",
    "\n",
    "# 打印聚类数\n",
    "n_clusters_ = len(set(labels))\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of miss start block in train data 271285\n",
      "The number of miss end block in train data 274566\n",
      "The number of miss start block in test data 11519\n"
     ]
    }
   ],
   "source": [
    "# 训练集聚类label\n",
    "info = pd.DataFrame(X[:trL,:], columns=['lat', 'lon'])\n",
    "info['block_id'] = labels[:trL]\n",
    "clear_info = info.loc[info.block_id != -1, :]\n",
    "print('The number of miss start block in train data', (info.block_id.iloc[:trL//2] == -1).sum())\n",
    "print('The number of miss end block in train data', (info.block_id.iloc[trL//2:] == -1).sum())\n",
    "# 测试集聚类label\n",
    "test_info = pd.DataFrame(X[trL:,:], columns=['lat', 'lon'])\n",
    "test_info['block_id'] = labels[trL:]\n",
    "print('The number of miss start block in test data', (test_info.block_id == -1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of good training data 1033722\n",
      "saving new train & test data\n"
     ]
    }
   ],
   "source": [
    "# 将聚类label拼接到训练集和测试集上\n",
    "train['start_block'] = info.block_id.iloc[:trL//2].values\n",
    "train['end_block'] = info.block_id.iloc[trL//2:].values\n",
    "test['start_block'] = test_info.block_id.values\n",
    "good_train_idx = (train.start_block != -1) & (train.end_block != -1)\n",
    "print('The number of good training data', good_train_idx.sum())\n",
    "good_train = train.loc[good_train_idx, :]\n",
    "print('saving new train & test data')\n",
    "good_train.to_csv('./chuxing/good_train.csv', index=None)\n",
    "test.to_csv('./chuxing/good_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为训练集和测试集生成is_holiday 和 hour字段\n",
    "def transformer(df):\n",
    "    special_holiday = ['2018-01-01'] + ['2018-02-%d' % d for d in range(15, 22)] + \\\n",
    "                      ['2018-04-%2d' % d for d in range(5, 8)] + \\\n",
    "                      ['2018-04-%d' % d for d in range(29, 31)] + ['2018-05-01'] +\\\n",
    "                      ['2018-06-%d' % d for d in range(16, 19)] + \\\n",
    "                      ['2018-09-%d' % d for d in range(22, 25)] + \\\n",
    "                      ['2018-10-%2d' % d for d in range(1, 8)]\n",
    "    special_workday = ['2018-02-%d' % d for d in [11, 24]] + \\\n",
    "                      ['2018-04-08'] + ['2018-04-28'] + \\\n",
    "                      ['2018-09-%d' % d for d in range(29, 31)]\n",
    "    for t_col in ['start_time']:\n",
    "        tmp = df[t_col].map(pd.Timestamp)\n",
    "        df['hour'] = tmp.map(lambda t: t.hour // 3)\n",
    "        df['half'] = tmp.map(lambda t: t.minute // 30)\n",
    "        df['day'] = tmp.map(lambda t: t.dayofweek)\n",
    "        tmp_date = df[t_col].map(lambda s: s.split(' ')[0])\n",
    "        not_spworkday_idx = ~tmp_date.isin(special_workday)\n",
    "        spholiday_idx = tmp_date.isin(special_holiday)\n",
    "        weekend_idx = (df['day'] >= 5)\n",
    "        df['is_holiday'] = ((weekend_idx & not_spworkday_idx) | spholiday_idx).astype(int)\n",
    "\n",
    "train = pd.read_csv('./chuxing/good_train.csv', low_memory=False)\n",
    "test = pd.read_csv('./chuxing/good_test.csv', low_memory=False)\n",
    "transformer(train)\n",
    "transformer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating P(start_block|end_block)\n",
      "   end_block  start_block  P(start_block|end_block)\n",
      "0          0            0                  0.634146\n",
      "1          0            9                  0.073171\n",
      "2          0        10617                  0.048780\n",
      "3          2            9                  0.275862\n",
      "4          2            3                  0.103448\n",
      "calculating P(out_id|end_block)\n",
      "calculating P(is_holiday|end_block)\n",
      "calculating P((is_holiday, hour)|end_block)\n",
      "   end_block  is_holiday  hour  P((is_holiday, hour)|end_block)\n",
      "0          0           0     2                         0.193548\n",
      "1          0           0     3                         0.322581\n",
      "2          0           0     4                         0.322581\n",
      "3          0           0     5                         0.387097\n",
      "4          0           0     6                         0.193548\n",
      "calculating P(day|end_block)\n",
      "calculating P(hour|end_block)\n",
      "calculating P((hour,half)|end_block)\n"
     ]
    }
   ],
   "source": [
    "# 根据训练集 计算朴素贝叶斯算法需要使用的 条件概率\n",
    "Probability = {}\n",
    "## P(start_block|end_block)\n",
    "name = 'start_block'\n",
    "pname = 'P(start_block|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: (1.0 * g[name].value_counts()) / (len(g) + 10)\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index()\n",
    "tmp.columns = ['end_block', name, pname]\n",
    "print(tmp.head())\n",
    "Probability[pname] = tmp\n",
    "## P(out_id|end_block)\n",
    "name = 'out_id'\n",
    "pname = 'P(out_id|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: (1.0 * g[name].value_counts()) / (len(g) + 10)\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index()\n",
    "tmp.columns = ['end_block', name, pname]\n",
    "Probability[pname] = tmp\n",
    "## P(is_holiday|end_block)\n",
    "name = 'is_holiday'\n",
    "pname = 'P(is_holiday|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: (1.0 * g[name].value_counts() + 3.) / (len(g) + 10)\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index()\n",
    "tmp.columns = ['end_block', name, pname]\n",
    "Probability[pname] = tmp\n",
    "## P((is_holiday, hour)|end_block)\n",
    "pname = 'P((is_holiday, hour)|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: (5 + 1.0 * g.groupby(['is_holiday', 'hour']).size()) / (len(g))\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index().rename(columns={0: pname})\n",
    "print(tmp.head())\n",
    "Probability[pname] = tmp\n",
    "## P(day|end_block)\n",
    "name = 'day'\n",
    "pname = 'P(day|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: 1.0 * g[name].value_counts() / len(g)\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index()\n",
    "tmp.columns = ['end_block', name, pname]\n",
    "Probability[pname] = tmp\n",
    "## P(hour|end_block)\n",
    "name = 'hour'\n",
    "pname = 'P(hour|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: 1.0 * g[name].value_counts() / len(g)\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index()\n",
    "tmp.columns = ['end_block', name, pname]\n",
    "Probability[pname] = tmp\n",
    "## P((hour,half)|end_block)\n",
    "pname = 'P((hour,half)|end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp_func = lambda g: 1.0 * g.groupby(['hour', 'half']).size() / len(g)\n",
    "tmp = train.groupby('end_block').apply(tmp_func).reset_index().rename(columns={0: pname})\n",
    "Probability[pname] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating P(end_block)\n"
     ]
    }
   ],
   "source": [
    "# 根据训练集 计算先验概率\n",
    "pname = 'P(end_block)'\n",
    "print('calculating %s' % pname)\n",
    "tmp = train.end_block.value_counts().reset_index()\n",
    "tmp.columns = ['end_block', pname]\n",
    "Probability[pname] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "223746\n",
      "0.006369426751592357 732126\n",
      "897409\n",
      "1017007\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "## 计算后验概率 \n",
    "## P(end_block|(start_block, out_id, is_holiday, hour)) = P(end_block) *\n",
    "##                         P(start_block|end_block) * P(out_id|end_block) * P((is_holiday, hour)|end_block)\n",
    "is_local = False  # 是否线下验证\n",
    "if is_local:\n",
    "    predict_info = train.copy()\n",
    "    predict_info = predict_info.rename(columns={'end_block': 'true_end_block', 'end_lat': 'true_end_lat', 'end_lon': 'true_end_lon'})\n",
    "else:\n",
    "    predict_info = test.copy()\n",
    "##\n",
    "predict_info = predict_info.merge(Probability['P(out_id|end_block)'], on='out_id', how='left')\n",
    "print(predict_info['P(out_id|end_block)'].isnull().sum())\n",
    "predict_info['P(out_id|end_block)'] = predict_info['P(out_id|end_block)'].fillna(1e-5)\n",
    "##\n",
    "predict_info = predict_info.merge(Probability['P(is_holiday|end_block)'], on=['is_holiday', 'end_block'], how='left')\n",
    "print(predict_info['P(is_holiday|end_block)'].isnull().sum())\n",
    "predict_info['P(is_holiday|end_block)'] = predict_info['P(is_holiday|end_block)'].fillna(1e-4)\n",
    "##\n",
    "predict_info = predict_info.merge(Probability['P(day|end_block)'], on=['day', 'end_block'], how='left')\n",
    "print(predict_info['P(day|end_block)'].min(), predict_info['P(day|end_block)'].isnull().sum())\n",
    "predict_info['P(day|end_block)'] = predict_info['P(day|end_block)'].fillna(1e-4)\n",
    "##\n",
    "predict_info = predict_info.merge(Probability['P((is_holiday, hour)|end_block)'], on=['is_holiday', 'hour', 'end_block'], how='left')\n",
    "print(predict_info['P((is_holiday, hour)|end_block)'].isnull().sum())\n",
    "predict_info['P((is_holiday, hour)|end_block)'] = predict_info['P((is_holiday, hour)|end_block)'].fillna(1e-4)\n",
    "##\n",
    "predict_info = predict_info.merge(Probability['P(start_block|end_block)'], on=['start_block', 'end_block'], how='left')\n",
    "print(predict_info['P(start_block|end_block)'].isnull().sum())\n",
    "predict_info['P(start_block|end_block)'] = predict_info['P(start_block|end_block)'].fillna(1e-5)\n",
    "##\n",
    "predict_info = predict_info.merge(Probability['P(end_block)'], on='end_block', how='left')\n",
    "print(predict_info['P(end_block)'].isnull().sum())\n",
    "predict_info['P(end_block)'] = predict_info['P(end_block)'].fillna(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_info['P(end_block|(start_block, out_id, is_holiday, hour))'] = predict_info['P((is_holiday, hour)|end_block)'] * \\\n",
    "                                                    predict_info['P(out_id|end_block)'] * \\\n",
    "                                                    predict_info['P(start_block|end_block)'] * \\\n",
    "                                                    predict_info['P(end_block)']\n",
    "which_probability = 'P(end_block|(start_block, out_id, is_holiday, hour))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start_lat     start_lon       end_lat       end_lon\n",
      "count  1.479000e+06  1.479000e+06  1.479000e+06  1.479000e+06\n",
      "mean   3.192510e+01  1.105811e+02  3.192317e+01  1.105630e+02\n",
      "std    5.688539e+00  8.944754e+00  5.650678e+00  8.876900e+00\n",
      "min    1.952510e+01  7.588308e+01  1.822312e+01  7.570830e+01\n",
      "25%    2.800811e+01  1.045850e+02  2.804389e+01  1.046645e+02\n",
      "50%    3.116697e+01  1.124626e+02  3.116691e+01  1.123717e+02\n",
      "75%    3.641346e+01  1.179807e+02  3.638166e+01  1.178508e+02\n",
      "max    5.348745e+01  1.342959e+02  4.974384e+01  1.342885e+02\n"
     ]
    }
   ],
   "source": [
    "# 生成每个聚类label的经纬度\n",
    "block_lat_lon = train.groupby('end_block')[['end_lat', 'end_lon']].mean().reset_index()\n",
    "predict_info = predict_info.merge(block_lat_lon, on='end_block', how='left')\n",
    "print(predict_info[['start_lat', 'start_lon', 'end_lat', 'end_lon']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "                                               r_key  start_lat   start_lon  \\\n",
      "0  f6fa6b2a1fa250b3_SDK-XJ_eed80f24f496fc9a59f49e...  43.943356  125.377718   \n",
      "1  a584728d1eb0fb5b_SDK-XJ_d60de6f0b8121b07383e80...  43.886501  125.272971   \n",
      "2  7308d46abc5ec4d0_SDK-XJ_6dd3f0f118e9813c51ed22...  43.867917  125.307853   \n",
      "3  7038defae966f837_SDK-XJ_c596c8fd60e6e6cad14518...  32.843961  115.864957   \n",
      "4  d4324c1d7d32d377_SDK-XJ_181a752a238a3f720eb378...  22.711616  113.318815   \n",
      "\n",
      "     end_lat     end_lon  \n",
      "0  43.894193  125.256641  \n",
      "1  43.882533  125.269936  \n",
      "2  43.794128  125.298256  \n",
      "3  35.859452  104.098735  \n",
      "4  22.694832  113.298214  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 58097 entries, 0 to 58096\n",
      "Data columns (total 5 columns):\n",
      "r_key        58097 non-null object\n",
      "start_lat    58097 non-null float64\n",
      "start_lon    58097 non-null float64\n",
      "end_lat      58097 non-null float64\n",
      "end_lon      58097 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "predict_result = predict_info.groupby('r_key').apply(lambda g: g.loc[g[which_probability].idxmax(), :]).reset_index(drop=True)\n",
    "if not is_local:\n",
    "    output_result = test[['r_key', 'start_lat', 'start_lon']].merge(predict_result[['r_key', 'end_lat', 'end_lon']], on='r_key', how='left')\n",
    "    print(output_result.end_lat.isnull().sum())\n",
    "    # 冷启动暂时用其实经纬度作为预测结果 \n",
    "    nan_idx = output_result.end_lat.isnull()\n",
    "    output_result.loc[nan_idx, 'end_lat'] = output_result['start_lat'][nan_idx]\n",
    "    output_result.loc[nan_idx, 'end_lon'] = output_result['start_lon'][nan_idx]\n",
    "    #output_result[['start_lat', 'end_lat', 'end_lon']].describe()\n",
    "    print(output_result.head())\n",
    "    print(output_result.info())\n",
    "    output_result[['r_key', 'end_lat', 'end_lon']].to_csv('./chuxing/baye1s.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
